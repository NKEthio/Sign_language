{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\udd1f American Sign Language (ASL) Interpreter - Educational Project",
        "",
        "## \ud83d\udcda Welcome to Your First Machine Learning Project!",
        "",
        "This notebook will guide you through creating an **American Sign Language (ASL) interpreter** that can recognize hand signs and translate them into letters. This is a complete beginner-friendly tutorial with step-by-step explanations.",
        "",
        "### \ud83c\udfaf What You'll Learn:",
        "1. **Understanding the Problem**: What is ASL and why is it important?",
        "2. **Dataset Requirements**: What data we need and how to get it",
        "3. **Data Preprocessing**: Preparing images for machine learning",
        "4. **Building a Model**: Creating a Convolutional Neural Network (CNN)",
        "5. **Training**: Teaching the model to recognize signs",
        "6. **Testing**: Evaluating how well our model works",
        "7. **Real-time Prediction**: Using the model to recognize new signs",
        "",
        "### \u26a1 Before You Start:",
        "- **Runtime**: Go to `Runtime` \u2192 `Change runtime type` \u2192 Select `GPU` for faster training",
        "- **Execution**: Run each cell in order by pressing `Shift + Enter`",
        "- **Time**: This project takes about 20-30 minutes to complete",
        "",
        "Let's begin! \ud83d\ude80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83d\udcd6 Part 1: Understanding the Problem",
        "",
        "### What is American Sign Language (ASL)?",
        "ASL is a complete, natural language that serves as the predominant sign language of Deaf communities in the United States and parts of Canada. It uses hand shapes, movements, and facial expressions to communicate.",
        "",
        "### Why Build an ASL Interpreter?",
        "- **Accessibility**: Help bridge communication gaps between deaf and hearing communities",
        "- **Education**: Learn ASL more easily with instant feedback",
        "- **Technology**: Understand how computer vision and machine learning work together",
        "",
        "### What We're Building:",
        "We'll create a system that can:",
        "- Recognize hand signs for letters A-Z (except J and Z which require motion)",
        "- Convert these signs into text",
        "- Work with images or webcam input",
        "",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 Part 2: Setting Up the Environment",
        "",
        "### What are we installing?",
        "- **TensorFlow/Keras**: For building and training our neural network",
        "- **OpenCV**: For image processing and webcam access",
        "- **Matplotlib**: For visualizing data and results",
        "- **NumPy**: For numerical operations",
        "- **scikit-learn**: For data splitting and metrics",
        "",
        "Let's install and import everything we need:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install required packages (most are already in Colab)",
        "import sys",
        "print(\"Installing packages...\")",
        "!pip install -q opencv-python-headless",
        "print(\"\u2705 Installation complete!\\n\")",
        "",
        "# Import all necessary libraries",
        "print(\"Importing libraries...\")",
        "import numpy as np",
        "import pandas as pd",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "import cv2",
        "import os",
        "import random",
        "from sklearn.model_selection import train_test_split",
        "from sklearn.metrics import classification_report, confusion_matrix",
        "",
        "import tensorflow as tf",
        "from tensorflow import keras",
        "from tensorflow.keras import layers, models",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator",
        "from tensorflow.keras.utils import to_categorical",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau",
        "",
        "import warnings",
        "warnings.filterwarnings('ignore')",
        "",
        "# Set random seeds for reproducibility",
        "np.random.seed(42)",
        "tf.random.set_seed(42)",
        "",
        "print(\"\u2705 All libraries imported successfully!\")",
        "print(f\"TensorFlow version: {tf.__version__}\")",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83d\udcca Part 3: Dataset Requirements and Acquisition",
        "",
        "### What Dataset Do We Need?",
        "",
        "For an ASL interpreter, we need:",
        "1. **Images of hand signs** for each letter (A-Z, excluding J and Z)",
        "2. **Multiple examples** per letter (at least 500-1000 images per class)",
        "3. **Consistent format**: Same size, similar backgrounds",
        "4. **Variety**: Different hands, skin tones, lighting conditions",
        "",
        "### Dataset Specifications:",
        "- **Format**: JPEG or PNG images",
        "- **Size**: 28x28 or 64x64 pixels (will be resized)",
        "- **Classes**: 24 letters (A-Z except J and Z which require motion)",
        "- **Structure**: Organized in folders by letter",
        "",
        "### Where to Get the Dataset:",
        "",
        "We'll use the **Sign Language MNIST** dataset, which is perfect for beginners:",
        "- Available on Kaggle: https://www.kaggle.com/datamunge/sign-language-mnist",
        "- Contains 27,455 training images and 7,172 test images",
        "- Images are 28x28 pixels, grayscale",
        "- Already labeled and organized",
        "",
        "### How to Download:",
        "",
        "**Option 1: Direct CSV Download (We'll use this)**",
        "The dataset is available as CSV files which we'll download directly.",
        "",
        "**Option 2: Using Kaggle API**",
        "1. Get your Kaggle API key from kaggle.com/account",
        "2. Upload kaggle.json to Colab",
        "3. Use: `!kaggle datasets download -d datamunge/sign-language-mnist`",
        "",
        "Let's download the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Download the Sign Language MNIST dataset",
        "print(\"\ud83d\udce5 Downloading ASL dataset...\\n\")",
        "",
        "# Download training data",
        "!wget -q https://raw.githubusercontent.com/mon95/Sign-Language-and-Static-gesture-recognition-using-sklearn/master/CSV/sign_mnist_train.csv",
        "",
        "# Download test data",
        "!wget -q https://raw.githubusercontent.com/mon95/Sign-Language-and-Static-gesture-recognition-using-sklearn/master/CSV/sign_mnist_test.csv",
        "",
        "print(\"\u2705 Dataset downloaded successfully!\\n\")",
        "",
        "# Verify files exist",
        "if os.path.exists('sign_mnist_train.csv') and os.path.exists('sign_mnist_test.csv'):",
        "    train_size = os.path.getsize('sign_mnist_train.csv') / (1024 * 1024)",
        "    test_size = os.path.getsize('sign_mnist_test.csv') / (1024 * 1024)",
        "    print(f\"Training file size: {train_size:.2f} MB\")",
        "    print(f\"Test file size: {test_size:.2f} MB\")",
        "else:",
        "    print(\"\u26a0\ufe0f Error: Dataset files not found!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83d\udd0d Part 4: Exploring the Dataset",
        "",
        "### Understanding the Data Structure",
        "",
        "Let's load and explore our dataset to understand what we're working with:",
        "- Each row represents one image",
        "- First column is the label (0-25 for A-Z, excluding J=9 and Z=25)",
        "- Remaining 784 columns are pixel values (28x28 = 784 pixels)",
        "- Pixel values range from 0 (black) to 255 (white)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the datasets",
        "print(\"\ud83d\udcc2 Loading datasets...\\n\")",
        "train_df = pd.read_csv('sign_mnist_train.csv')",
        "test_df = pd.read_csv('sign_mnist_test.csv')",
        "",
        "print(\"Dataset Information:\")",
        "print(\"=\"*50)",
        "print(f\"Training samples: {len(train_df)}\")",
        "print(f\"Test samples: {len(test_df)}\")",
        "print(f\"Features per image: {len(train_df.columns) - 1}\")",
        "print(f\"Image dimensions: 28 x 28 pixels\\n\")",
        "",
        "# Display first few rows",
        "print(\"First 5 rows of training data:\")",
        "print(train_df.head())",
        "",
        "# Check class distribution",
        "print(\"\\nClass Distribution in Training Set:\")",
        "print(\"=\"*50)",
        "label_counts = train_df['label'].value_counts().sort_index()",
        "print(label_counts)",
        "",
        "# Create label mapping (A=0, B=1, ..., Y=24, excluding J and Z)",
        "label_map = {i: chr(65 + i) if i < 9 else chr(65 + i + 1) for i in range(25)}",
        "print(\"\\nLabel to Letter Mapping:\")",
        "print(label_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Sample Images",
        "",
        "Let's see what our ASL signs look like!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Function to display sample images",
        "def display_samples(dataframe, num_samples=24):",
        "    \"\"\"",
        "    Display sample images from the dataset",
        "    \"\"\"",
        "    fig, axes = plt.subplots(4, 6, figsize=(15, 10))",
        "    fig.suptitle('Sample ASL Signs from Training Dataset', fontsize=16, fontweight='bold')",
        "    ",
        "    axes = axes.ravel()",
        "    ",
        "    for i in range(num_samples):",
        "        # Get a random sample from each class",
        "        if i < len(label_map):",
        "            sample = dataframe[dataframe['label'] == i].sample(1)",
        "            if len(sample) > 0:",
        "                # Extract pixel values and reshape to 28x28",
        "                pixels = sample.iloc[0, 1:].values.reshape(28, 28)",
        "                ",
        "                # Display image",
        "                axes[i].imshow(pixels, cmap='gray')",
        "                axes[i].set_title(f'Letter: {label_map[i]}', fontweight='bold')",
        "                axes[i].axis('off')",
        "    ",
        "    plt.tight_layout()",
        "    plt.show()",
        "",
        "# Display samples",
        "display_samples(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize class distribution",
        "plt.figure(figsize=(14, 5))",
        "",
        "plt.subplot(1, 2, 1)",
        "labels_with_letters = [label_map[i] for i in label_counts.index]",
        "plt.bar(labels_with_letters, label_counts.values, color='steelblue', alpha=0.7)",
        "plt.xlabel('ASL Letter', fontweight='bold')",
        "plt.ylabel('Number of Samples', fontweight='bold')",
        "plt.title('Training Set - Class Distribution', fontweight='bold')",
        "plt.xticks(rotation=0)",
        "plt.grid(axis='y', alpha=0.3)",
        "",
        "plt.subplot(1, 2, 2)",
        "test_label_counts = test_df['label'].value_counts().sort_index()",
        "test_labels_with_letters = [label_map[i] for i in test_label_counts.index]",
        "plt.bar(test_labels_with_letters, test_label_counts.values, color='coral', alpha=0.7)",
        "plt.xlabel('ASL Letter', fontweight='bold')",
        "plt.ylabel('Number of Samples', fontweight='bold')",
        "plt.title('Test Set - Class Distribution', fontweight='bold')",
        "plt.xticks(rotation=0)",
        "plt.grid(axis='y', alpha=0.3)",
        "",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(\"\\n\ud83d\udcca Observation: The dataset is fairly balanced across all letters!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83d\udd04 Part 5: Data Preprocessing",
        "",
        "### Why Preprocess Data?",
        "",
        "Machine learning models work better when data is:",
        "1. **Normalized**: Values between 0 and 1 instead of 0-255",
        "2. **Properly shaped**: Organized in the right format for the model",
        "3. **Encoded**: Labels converted to one-hot encoding",
        "",
        "### Steps:",
        "1. Separate features (X) and labels (y)",
        "2. Reshape images to 28x28x1 (height x width x channels)",
        "3. Normalize pixel values to 0-1 range",
        "4. One-hot encode labels",
        "5. Split training data into train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\ud83d\udd04 Preprocessing data...\\n\")",
        "",
        "# Step 1: Separate features and labels",
        "X_train = train_df.drop('label', axis=1).values",
        "y_train = train_df['label'].values",
        "",
        "X_test = test_df.drop('label', axis=1).values",
        "y_test = test_df['label'].values",
        "",
        "print(f\"\u2705 Separated features and labels\")",
        "print(f\"   Training features shape: {X_train.shape}\")",
        "print(f\"   Training labels shape: {y_train.shape}\\n\")",
        "",
        "# Step 2: Reshape images (784,) -> (28, 28, 1)",
        "X_train = X_train.reshape(-1, 28, 28, 1)",
        "X_test = X_test.reshape(-1, 28, 28, 1)",
        "",
        "print(f\"\u2705 Reshaped images to 28x28x1\")",
        "print(f\"   New training shape: {X_train.shape}\\n\")",
        "",
        "# Step 3: Normalize pixel values (0-255 -> 0-1)",
        "X_train = X_train.astype('float32') / 255.0",
        "X_test = X_test.astype('float32') / 255.0",
        "",
        "print(f\"\u2705 Normalized pixel values\")",
        "print(f\"   Min value: {X_train.min()}, Max value: {X_train.max()}\\n\")",
        "",
        "# Step 4: One-hot encode labels",
        "# Example: label 0 (A) -> [1, 0, 0, ..., 0]",
        "#          label 1 (B) -> [0, 1, 0, ..., 0]",
        "num_classes = 25  # A-Z excluding J and Z",
        "y_train_encoded = to_categorical(y_train, num_classes)",
        "y_test_encoded = to_categorical(y_test, num_classes)",
        "",
        "print(f\"\u2705 One-hot encoded labels\")",
        "print(f\"   Number of classes: {num_classes}\")",
        "print(f\"   Encoded label shape: {y_train_encoded.shape}\\n\")",
        "",
        "# Step 5: Split into training and validation sets (80-20 split)",
        "X_train_final, X_val, y_train_final, y_val = train_test_split(",
        "    X_train, y_train_encoded, test_size=0.2, random_state=42, stratify=y_train",
        ")",
        "",
        "print(f\"\u2705 Split data into train and validation\")",
        "print(f\"   Training samples: {len(X_train_final)}\")",
        "print(f\"   Validation samples: {len(X_val)}\")",
        "print(f\"   Test samples: {len(X_test)}\\n\")",
        "",
        "print(\"=\"*50)",
        "print(\"\ud83d\udcca PREPROCESSING COMPLETE!\")",
        "print(\"=\"*50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83c\udfd7\ufe0f Part 6: Building the Model",
        "",
        "### What is a Convolutional Neural Network (CNN)?",
        "",
        "A CNN is a type of neural network that's excellent for image recognition. It works by:",
        "1. **Convolution layers**: Detect features like edges, curves, and patterns",
        "2. **Pooling layers**: Reduce image size while keeping important information",
        "3. **Dense layers**: Make final predictions based on detected features",
        "",
        "### Our Model Architecture:",
        "",
        "```",
        "Input (28x28x1)",
        "    \u2193",
        "Conv2D (32 filters) + ReLU",
        "    \u2193",
        "MaxPooling",
        "    \u2193",
        "Conv2D (64 filters) + ReLU",
        "    \u2193",
        "MaxPooling",
        "    \u2193",
        "Conv2D (128 filters) + ReLU",
        "    \u2193",
        "Flatten",
        "    \u2193",
        "Dense (128 units) + ReLU + Dropout",
        "    \u2193",
        "Output (25 classes) + Softmax",
        "```",
        "",
        "Let's build it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\ud83c\udfd7\ufe0f Building the CNN model...\\n\")",
        "",
        "# Create the model",
        "model = models.Sequential([",
        "    # First Convolutional Block",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), ",
        "                  padding='same', name='conv1'),",
        "    layers.BatchNormalization(),",
        "    layers.MaxPooling2D((2, 2), name='pool1'),",
        "    ",
        "    # Second Convolutional Block",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2'),",
        "    layers.BatchNormalization(),",
        "    layers.MaxPooling2D((2, 2), name='pool2'),",
        "    ",
        "    # Third Convolutional Block",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3'),",
        "    layers.BatchNormalization(),",
        "    layers.MaxPooling2D((2, 2), name='pool3'),",
        "    ",
        "    # Flatten and Dense Layers",
        "    layers.Flatten(name='flatten'),",
        "    layers.Dense(128, activation='relu', name='dense1'),",
        "    layers.Dropout(0.5, name='dropout'),",
        "    layers.Dense(num_classes, activation='softmax', name='output')",
        "])",
        "",
        "# Compile the model",
        "model.compile(",
        "    optimizer='adam',",
        "    loss='categorical_crossentropy',",
        "    metrics=['accuracy']",
        ")",
        "",
        "print(\"\u2705 Model built successfully!\\n\")",
        "",
        "# Display model summary",
        "print(\"Model Architecture:\")",
        "print(\"=\"*70)",
        "model.summary()",
        "",
        "# Count parameters",
        "total_params = model.count_params()",
        "print(f\"\\n\ud83d\udcca Total trainable parameters: {total_params:,}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding the Model Parameters:",
        "",
        "- **Conv2D layers**: Learn to detect patterns in images",
        "- **BatchNormalization**: Stabilizes and speeds up training",
        "- **MaxPooling**: Reduces image size, focuses on important features",
        "- **Dropout**: Prevents overfitting by randomly disabling neurons during training",
        "- **Softmax**: Converts outputs to probabilities (0-1) for each class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83c\udf93 Part 7: Training the Model",
        "",
        "### What is Training?",
        "",
        "Training is the process where the model learns to recognize ASL signs by:",
        "1. Looking at many examples of each letter",
        "2. Making predictions",
        "3. Comparing predictions to actual labels",
        "4. Adjusting its internal parameters to improve accuracy",
        "",
        "### Training Parameters:",
        "- **Epochs**: Number of times the model sees the entire dataset (we'll use 30)",
        "- **Batch size**: Number of images processed at once (32)",
        "- **Validation**: Check performance on unseen data after each epoch",
        "",
        "### Callbacks:",
        "- **EarlyStopping**: Stop training if validation accuracy stops improving",
        "- **ReduceLROnPlateau**: Reduce learning rate when progress plateaus",
        "",
        "This will take 5-10 minutes. Let's train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set up data augmentation for better generalization",
        "datagen = ImageDataGenerator(",
        "    rotation_range=10,",
        "    width_shift_range=0.1,",
        "    height_shift_range=0.1,",
        "    zoom_range=0.1",
        ")",
        "",
        "# Define callbacks",
        "early_stopping = EarlyStopping(",
        "    monitor='val_accuracy',",
        "    patience=5,",
        "    restore_best_weights=True,",
        "    verbose=1",
        ")",
        "",
        "reduce_lr = ReduceLROnPlateau(",
        "    monitor='val_loss',",
        "    factor=0.5,",
        "    patience=3,",
        "    min_lr=0.00001,",
        "    verbose=1",
        ")",
        "",
        "print(\"\ud83c\udf93 Starting training...\")",
        "print(\"This will take approximately 5-10 minutes with GPU.\\n\")",
        "print(\"=\"*70)",
        "",
        "# Train the model",
        "history = model.fit(",
        "    datagen.flow(X_train_final, y_train_final, batch_size=32),",
        "    epochs=30,",
        "    validation_data=(X_val, y_val),",
        "    callbacks=[early_stopping, reduce_lr],",
        "    verbose=1",
        ")",
        "",
        "print(\"\\n\" + \"=\"*70)",
        "print(\"\u2705 Training complete!\")",
        "print(\"=\"*70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Training Progress",
        "",
        "Let's see how the model improved during training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot training history",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))",
        "",
        "# Accuracy plot",
        "ax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)",
        "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)",
        "ax1.set_title('Model Accuracy Over Time', fontweight='bold', fontsize=14)",
        "ax1.set_xlabel('Epoch', fontweight='bold')",
        "ax1.set_ylabel('Accuracy', fontweight='bold')",
        "ax1.legend(loc='lower right')",
        "ax1.grid(True, alpha=0.3)",
        "",
        "# Loss plot",
        "ax2.plot(history.history['loss'], label='Training Loss', linewidth=2)",
        "ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)",
        "ax2.set_title('Model Loss Over Time', fontweight='bold', fontsize=14)",
        "ax2.set_xlabel('Epoch', fontweight='bold')",
        "ax2.set_ylabel('Loss', fontweight='bold')",
        "ax2.legend(loc='upper right')",
        "ax2.grid(True, alpha=0.3)",
        "",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "# Print best results",
        "best_epoch = np.argmax(history.history['val_accuracy']) + 1",
        "best_val_acc = max(history.history['val_accuracy'])",
        "print(f\"\\n\ud83d\udcca Best Results:\")",
        "print(f\"   Best Epoch: {best_epoch}\")",
        "print(f\"   Best Validation Accuracy: {best_val_acc*100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83d\udcc8 Part 8: Evaluating the Model",
        "",
        "### Why Evaluate?",
        "",
        "We need to know how well our model performs on completely unseen data (test set).",
        "",
        "### Metrics:",
        "- **Accuracy**: Percentage of correct predictions",
        "- **Confusion Matrix**: Shows which letters are confused with each other",
        "- **Classification Report**: Detailed precision, recall, and F1-score per class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\ud83d\udcc8 Evaluating model on test set...\\n\")",
        "",
        "# Evaluate on test set",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=0)",
        "",
        "print(\"=\"*70)",
        "print(\"Test Results:\")",
        "print(\"=\"*70)",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")",
        "print(f\"Test Loss: {test_loss:.4f}\")",
        "print(\"=\"*70)",
        "",
        "# Make predictions",
        "y_pred = model.predict(X_test, verbose=0)",
        "y_pred_classes = np.argmax(y_pred, axis=1)",
        "",
        "# Classification report",
        "print(\"\\nDetailed Classification Report:\")",
        "print(\"=\"*70)",
        "target_names = [label_map[i] for i in range(num_classes)]",
        "print(classification_report(y_test, y_pred_classes, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Confusion Matrix",
        "cm = confusion_matrix(y_test, y_pred_classes)",
        "",
        "plt.figure(figsize=(16, 14))",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ",
        "            xticklabels=target_names, ",
        "            yticklabels=target_names,",
        "            cbar_kws={'label': 'Count'})",
        "plt.title('Confusion Matrix - ASL Letter Recognition', fontweight='bold', fontsize=16, pad=20)",
        "plt.xlabel('Predicted Letter', fontweight='bold', fontsize=12)",
        "plt.ylabel('True Letter', fontweight='bold', fontsize=12)",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(\"\\n\ud83d\udca1 Understanding the Confusion Matrix:\")",
        "print(\"   - Diagonal values (dark blue): Correct predictions\")",
        "print(\"   - Off-diagonal values: Misclassifications\")",
        "print(\"   - Larger numbers off-diagonal indicate confusion between those letters\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyzing Common Mistakes",
        "",
        "Let's identify which letters are most commonly confused:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find most confused pairs",
        "confusion_pairs = []",
        "for i in range(num_classes):",
        "    for j in range(num_classes):",
        "        if i != j and cm[i][j] > 0:",
        "            confusion_pairs.append((label_map[i], label_map[j], cm[i][j]))",
        "",
        "# Sort by confusion count",
        "confusion_pairs.sort(key=lambda x: x[2], reverse=True)",
        "",
        "print(\"\\n\ud83d\udd0d Top 10 Most Confused Letter Pairs:\")",
        "print(\"=\"*70)",
        "print(f\"{'True Letter':<15} {'Predicted As':<15} {'Count':<10}\")",
        "print(\"=\"*70)",
        "for true_letter, pred_letter, count in confusion_pairs[:10]:",
        "    print(f\"{true_letter:<15} {pred_letter:<15} {count:<10}\")",
        "",
        "print(\"\\n\ud83d\udca1 This information helps us understand which signs are visually similar!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83c\udfaf Part 9: Making Predictions",
        "",
        "### Testing with Random Samples",
        "",
        "Let's see how our model performs on individual images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def predict_and_visualize(model, X_data, y_data, num_samples=12):",
        "    \"\"\"",
        "    Visualize predictions on random samples",
        "    \"\"\"",
        "    # Select random samples",
        "    indices = random.sample(range(len(X_data)), num_samples)",
        "    ",
        "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))",
        "    fig.suptitle('Model Predictions on Random Test Samples', fontsize=16, fontweight='bold')",
        "    axes = axes.ravel()",
        "    ",
        "    for idx, i in enumerate(indices):",
        "        # Get image and true label",
        "        image = X_data[i]",
        "        true_label = y_data[i]",
        "        ",
        "        # Make prediction",
        "        prediction = model.predict(image.reshape(1, 28, 28, 1), verbose=0)",
        "        predicted_class = np.argmax(prediction)",
        "        confidence = prediction[0][predicted_class] * 100",
        "        ",
        "        # Get letter labels",
        "        true_letter = label_map[true_label]",
        "        pred_letter = label_map[predicted_class]",
        "        ",
        "        # Display",
        "        axes[idx].imshow(image.squeeze(), cmap='gray')",
        "        ",
        "        # Color code: green if correct, red if wrong",
        "        color = 'green' if true_label == predicted_class else 'red'",
        "        axes[idx].set_title(",
        "            f'True: {true_letter} | Pred: {pred_letter}\\nConfidence: {confidence:.1f}%',",
        "            color=color, fontweight='bold'",
        "        )",
        "        axes[idx].axis('off')",
        "    ",
        "    plt.tight_layout()",
        "    plt.show()",
        "",
        "# Visualize predictions",
        "predict_and_visualize(model, X_test, y_test, num_samples=12)",
        "",
        "print(\"\\n\ud83d\udca1 Legend:\")",
        "print(\"   \ud83d\udfe2 Green title = Correct prediction\")",
        "print(\"   \ud83d\udd34 Red title = Incorrect prediction\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83c\udfa5 Part 10: Interactive Prediction Function",
        "",
        "### Create a User-Friendly Prediction Function",
        "",
        "Let's create a function that can predict any ASL sign:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def predict_asl_sign(image_data, model, display=True):",
        "    \"\"\"",
        "    Predict ASL sign from image data",
        "    ",
        "    Args:",
        "        image_data: 28x28 numpy array or flattened 784 array",
        "        model: trained model",
        "        display: whether to display the image",
        "    ",
        "    Returns:",
        "        predicted_letter, confidence",
        "    \"\"\"",
        "    # Reshape if needed",
        "    if image_data.shape == (784,):",
        "        image_data = image_data.reshape(28, 28, 1)",
        "    elif image_data.shape == (28, 28):",
        "        image_data = image_data.reshape(28, 28, 1)",
        "    ",
        "    # Normalize if needed",
        "    if image_data.max() > 1.0:",
        "        image_data = image_data / 255.0",
        "    ",
        "    # Make prediction",
        "    prediction = model.predict(image_data.reshape(1, 28, 28, 1), verbose=0)",
        "    predicted_class = np.argmax(prediction)",
        "    confidence = prediction[0][predicted_class] * 100",
        "    predicted_letter = label_map[predicted_class]",
        "    ",
        "    if display:",
        "        plt.figure(figsize=(6, 6))",
        "        plt.imshow(image_data.squeeze(), cmap='gray')",
        "        plt.title(f'Predicted: {predicted_letter}\\nConfidence: {confidence:.2f}%', ",
        "                  fontweight='bold', fontsize=14)",
        "        plt.axis('off')",
        "        plt.show()",
        "        ",
        "        # Show top 5 predictions",
        "        top_5_idx = np.argsort(prediction[0])[-5:][::-1]",
        "        print(\"\\nTop 5 Predictions:\")",
        "        print(\"=\"*40)",
        "        for idx in top_5_idx:",
        "            print(f\"{label_map[idx]}: {prediction[0][idx]*100:.2f}%\")",
        "    ",
        "    return predicted_letter, confidence",
        "",
        "# Test the function",
        "print(\"\ud83c\udfaf Testing prediction function with a random test image:\\n\")",
        "random_idx = random.randint(0, len(X_test)-1)",
        "test_image = X_test[random_idx]",
        "true_letter = label_map[y_test[random_idx]]",
        "",
        "pred_letter, confidence = predict_asl_sign(test_image, model, display=True)",
        "print(f\"\\n\u2705 True letter: {true_letter}\")",
        "print(f\"{'\u2705' if pred_letter == true_letter else '\u274c'} Prediction: {pred_letter}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83d\udcbe Part 11: Saving the Model",
        "",
        "### Why Save the Model?",
        "",
        "After training, we want to save our model so we can:",
        "- Use it later without retraining",
        "- Deploy it in applications",
        "- Share it with others",
        "",
        "Let's save our trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save the model",
        "model_filename = 'asl_interpreter_model.h5'",
        "model.save(model_filename)",
        "print(f\"\u2705 Model saved as '{model_filename}'\")",
        "",
        "# Save model in TensorFlow SavedModel format (recommended)",
        "model_dir = 'asl_model_saved'",
        "model.save(model_dir)",
        "print(f\"\u2705 Model saved in SavedModel format at '{model_dir}'\")",
        "",
        "# To load the model later:",
        "print(\"\\n\ud83d\udca1 To load this model later, use:\")",
        "print(\"   loaded_model = tf.keras.models.load_model('asl_interpreter_model.h5')\")",
        "print(\"   or\")",
        "print(\"   loaded_model = tf.keras.models.load_model('asl_model_saved')\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83d\udcda Part 12: Educational Summary",
        "",
        "### What You've Learned! \ud83c\udf89",
        "",
        "Congratulations! You've successfully built an ASL interpreter. Here's what you accomplished:",
        "",
        "#### 1. **Data Science Skills**",
        "- \u2705 Downloaded and explored a real-world dataset",
        "- \u2705 Visualized data to understand it better",
        "- \u2705 Preprocessed data for machine learning",
        "- \u2705 Split data into training, validation, and test sets",
        "",
        "#### 2. **Machine Learning Skills**",
        "- \u2705 Built a Convolutional Neural Network from scratch",
        "- \u2705 Trained a model with data augmentation",
        "- \u2705 Used callbacks to improve training",
        "- \u2705 Evaluated model performance with multiple metrics",
        "",
        "#### 3. **Deep Learning Concepts**",
        "- \u2705 Convolutional layers for feature extraction",
        "- \u2705 Pooling layers for dimensionality reduction",
        "- \u2705 Dropout for preventing overfitting",
        "- \u2705 Batch normalization for stable training",
        "- \u2705 Softmax activation for multi-class classification",
        "",
        "#### 4. **Computer Vision**",
        "- \u2705 Image preprocessing and normalization",
        "- \u2705 Data augmentation techniques",
        "- \u2705 Understanding image classification",
        "",
        "### \ud83d\ude80 Next Steps",
        "",
        "To further improve this project:",
        "",
        "1. **Collect Your Own Data**",
        "   - Use a webcam to capture your own hand signs",
        "   - Add these to the training set",
        "",
        "2. **Improve the Model**",
        "   - Try different architectures (ResNet, MobileNet)",
        "   - Experiment with hyperparameters",
        "   - Use transfer learning",
        "",
        "3. **Add More Features**",
        "   - Include J and Z (motion letters)",
        "   - Add word recognition",
        "   - Create a real-time webcam interface",
        "",
        "4. **Deploy the Model**",
        "   - Create a web application with Flask/Streamlit",
        "   - Build a mobile app",
        "   - Deploy on cloud platforms",
        "",
        "### \ud83d\udcd6 Key Takeaways",
        "",
        "```",
        "Dataset Specs:",
        "  - Format: CSV files with pixel values",
        "  - Images: 28x28 grayscale",
        "  - Classes: 25 (A-Z excluding J and Z)",
        "  - Total samples: ~35,000",
        "",
        "Model Performance:",
        "  - Test Accuracy: ~95-99%",
        "  - Training Time: 5-10 minutes (with GPU)",
        "  - Model Size: ~2-3 MB",
        "",
        "Requirements:",
        "  - Python 3.7+",
        "  - TensorFlow 2.x",
        "  - NumPy, Pandas, Matplotlib",
        "  - Google Colab (free GPU)",
        "```",
        "",
        "### \ud83c\udf93 Educational Value",
        "",
        "This project teaches:",
        "- **Real-world application**: Helping deaf community",
        "- **End-to-end ML pipeline**: From data to deployment",
        "- **Best practices**: Data splitting, validation, callbacks",
        "- **Model evaluation**: Multiple metrics and visualization",
        "",
        "### \ud83e\udd1d Contributing to Accessibility",
        "",
        "Remember: This technology can help bridge communication gaps and make the world more accessible for everyone!",
        "",
        "---",
        "",
        "## \ud83d\udcdd Additional Resources",
        "",
        "### Learn More:",
        "- **ASL**: https://www.nad.org/resources/american-sign-language/",
        "- **TensorFlow**: https://www.tensorflow.org/tutorials",
        "- **CNN**: https://cs231n.github.io/",
        "- **Computer Vision**: https://opencv.org/",
        "",
        "### Datasets:",
        "- Sign Language MNIST: https://www.kaggle.com/datamunge/sign-language-mnist",
        "- ASL Alphabet: https://www.kaggle.com/grassknoted/asl-alphabet",
        "",
        "### Communities:",
        "- TensorFlow Forum: https://discuss.tensorflow.org/",
        "- r/MachineLearning: https://reddit.com/r/MachineLearning",
        "- Kaggle: https://www.kaggle.com/",
        "",
        "---",
        "",
        "**Thank you for completing this educational project! \ud83c\udf89**",
        "",
        "Keep learning and building amazing things! \ud83d\udcaa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## \ud83c\udfae BONUS: Interactive Demo",
        "",
        "Try the model yourself! Run the cell below to predict random test images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Interactive demo",
        "print(\"\ud83c\udfae Interactive ASL Prediction Demo\")",
        "print(\"=\"*70)",
        "print(\"Run this cell multiple times to see different predictions!\\n\")",
        "",
        "# Select 6 random images",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))",
        "fig.suptitle('\ud83e\udd1f ASL Sign Recognition - Interactive Demo', fontsize=16, fontweight='bold')",
        "axes = axes.ravel()",
        "",
        "for i in range(6):",
        "    idx = random.randint(0, len(X_test)-1)",
        "    image = X_test[idx]",
        "    true_label = y_test[idx]",
        "    ",
        "    # Predict",
        "    prediction = model.predict(image.reshape(1, 28, 28, 1), verbose=0)",
        "    predicted_class = np.argmax(prediction)",
        "    confidence = prediction[0][predicted_class] * 100",
        "    ",
        "    # Get letters",
        "    true_letter = label_map[true_label]",
        "    pred_letter = label_map[predicted_class]",
        "    ",
        "    # Display",
        "    axes[i].imshow(image.squeeze(), cmap='gray')",
        "    color = 'green' if true_label == predicted_class else 'red'",
        "    axes[i].set_title(",
        "        f'True: {true_letter}\\nPredicted: {pred_letter} ({confidence:.1f}%)',",
        "        color=color, fontweight='bold', fontsize=12",
        "    )",
        "    axes[i].axis('off')",
        "",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(\"\\n\ud83d\udca1 Try running this cell again to see more predictions!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}